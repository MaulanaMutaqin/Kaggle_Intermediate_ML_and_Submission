{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will work with data from the [Housing Prices Competition for Kaggle Learn Users](https://www.kaggle.com/c/home-data-for-ml-course).\n",
    "\n",
    "Run the next code cell without changes to load the training and validation sets in `X_train`, `X_valid`, `y_train`, and `y_valid`.  The test set is loaded in `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
      "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
      "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
      "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
      "\n",
      "  YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0   2008        WD         Normal     208500  \n",
      "1   2007        WD         Normal     181500  \n",
      "2   2008        WD         Normal     223500  \n",
      "3   2006        WD        Abnorml     140000  \n",
      "4   2008        WD         Normal     250000  \n",
      "\n",
      "[5 rows x 81 columns]\n",
      "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
      "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
      "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
      "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
      "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
      "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
      "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
      "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
      "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
      "\n",
      "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
      "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
      "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
      "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
      "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
      "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
      "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
      "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
      "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
      "\n",
      "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
      "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
      "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
      "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
      "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
      "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
      "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
      "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
      "\n",
      "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
      "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
      "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
      "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
      "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
      "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
      "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
      "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
      "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
      "\n",
      "[8 rows x 38 columns]\n",
      "Validation MAE: 29,653\n",
      "Max leaf nodes: 5 \t\t Mean Absolute Error: 35044\n",
      "Max leaf nodes: 25 \t\t Mean Absolute Error: 29016\n",
      "Max leaf nodes: 50 \t\t Mean Absolute Error: 27405\n",
      "Max leaf nodes: 100 \t\t Mean Absolute Error: 27282\n",
      "Max leaf nodes: 250 \t\t Mean Absolute Error: 27893\n",
      "Max leaf nodes: 500 \t\t Mean Absolute Error: 29454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code you have previously used to load data\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "home_data = pd.read_csv(r'C:\\Users\\Asus\\Documents\\Python\\csv file\\train.csv', sep=',')\n",
    "print(home_data.head())\n",
    "print(home_data.describe())\n",
    "\n",
    "# Create target object and call it y\n",
    "y = home_data.SalePrice\n",
    "# Create X\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = home_data[features]\n",
    "\n",
    "# Split into validation and training data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Specify Model\n",
    "iowa_model = DecisionTreeRegressor(random_state=1)\n",
    "# Fit Model\n",
    "iowa_model.fit(train_X, train_y)\n",
    "\n",
    "# Make validation predictions and calculate mean absolute error\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE: {:,.0f}\".format(val_mae))\n",
    "\n",
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)\n",
    "\n",
    "# Compare Different Tree Sizes\n",
    "candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\n",
    "# Write loop to find the ideal tree size from candidate_max_leaf_nodes\n",
    "for max_leaf_nodes in candidate_max_leaf_nodes:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print('Max leaf nodes: %d \\t\\t Mean Absolute Error: %d' % (max_leaf_nodes, my_mae))\n",
    "\n",
    "# Store the best value of max_leaf_nodes (it will be either 5, 25, 50, 100, 250 or 500)\n",
    "best_tree_size = 100\n",
    "\n",
    "# Fill in argument to make optimal size and uncomment\n",
    "final_model = DecisionTreeRegressor(max_leaf_nodes=best_tree_size, random_state=1)\n",
    "\n",
    "# fit the final model and uncomment the next two lines\n",
    "final_model.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4484c28bae1de224b39b1e20eaed8996fc1e089d98419c1c635748a34569e3eb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
